searchNodes=[{"doc":"Hauptmodul des Neuralen Netzwerks.","ref":"ElixirNeuralNetwork.html","title":"ElixirNeuralNetwork","type":"module"},{"doc":"","ref":"ElixirNeuralNetwork.html#main/0","title":"ElixirNeuralNetwork.main/0","type":"function"},{"doc":"Modul für wiederverwendete algebraische Funktionen. Diese enthalten u. a. die Aktivierungsfunktion.","ref":"ElixirNeuralNetwork.Algebra.html","title":"ElixirNeuralNetwork.Algebra","type":"module"},{"doc":"Logistische Funktion $\\sigma(x)$, eine Funktion mit einem S-förmigen Graphen. Im wesentlichen nur eine skalierte &amp; verschobene hyperbolische Tangensfunktion. https://de.wikipedia.org/wiki/Logistische_Funktion Wird für dieses Netz als Aktivierungsfunktion verwendet.","ref":"ElixirNeuralNetwork.Algebra.html#logistic/1","title":"ElixirNeuralNetwork.Algebra.logistic/1","type":"function"},{"doc":"Benutzen der Reziprokenregel zum Ableiten von $\\sigma(x)$. https://de.wikipedia.org/wiki/Reziprokenregel","ref":"ElixirNeuralNetwork.Algebra.html#logistic_prime/1","title":"ElixirNeuralNetwork.Algebra.logistic_prime/1","type":"function"},{"doc":"Implementation der numpy-Funktion randn() für 2 Dimensionen. Generieret zufällige Werte einer Normalverteilung mit einer Standardabweichung / Varianz $\\sigma = 1$ und einem Erwartungswert $\\mu = 0$. Erstellt eine 2-Dimensionale Matrix, bei der jede Reihe durch eine Liste dargestellt wird. https://de.wikipedia.org/wiki/Normalverteilung","ref":"ElixirNeuralNetwork.Algebra.html#randn/2","title":"ElixirNeuralNetwork.Algebra.randn/2","type":"function"},{"doc":"Modul für die Kernlogik des neuralen Netzwerkes.","ref":"ElixirNeuralNetwork.Network.html","title":"ElixirNeuralNetwork.Network","type":"module"},{"doc":"Importiert den MNIST-Datensatz iex&gt; download ( ) { images , labels }","ref":"ElixirNeuralNetwork.Network.html#download/0","title":"ElixirNeuralNetwork.Network.download/0","type":"function"},{"doc":"","ref":"ElixirNeuralNetwork.Network.html#init/1","title":"ElixirNeuralNetwork.Network.init/1","type":"function"},{"doc":"Bereitet den Datensatz zur Verarbeitung im neuralen Netz vor. Teilt die Daten in Trainings- Validations- und Testdaten ein. iex&gt; transform_images ( { images , labels } ) { training_data , validation_data , test_data }","ref":"ElixirNeuralNetwork.Network.html#prepare_data/0","title":"ElixirNeuralNetwork.Network.prepare_data/0","type":"function"},{"doc":"","ref":"ElixirNeuralNetwork.Network.html#sgd/0","title":"ElixirNeuralNetwork.Network.sgd/0","type":"function"},{"doc":"","ref":"ElixirNeuralNetwork.Network.html#transform_images/1","title":"ElixirNeuralNetwork.Network.transform_images/1","type":"function"},{"doc":"","ref":"ElixirNeuralNetwork.Network.html#transform_labels/1","title":"ElixirNeuralNetwork.Network.transform_labels/1","type":"function"},{"doc":"Einfaches neurales Netz zum erkennen von handschriftlich geschriebenen Zahlen. Basierend auf Michael Nielsen's &quot;Neural Networks and Deep Learning&quot; und dem &quot;MNIST&quot; Datensatz .","ref":"readme.html","title":"Elixir Neurales Netz","type":"extras"},{"doc":"Die folgenden Ressourcen zu der Sprache Elixir und neuralen Netzen habe ich mir zu Hilfe genommen. Das eben erwähnte Buch Neural Networks and Deep Learning von Michael Nielson Den udemy-Kurs The Complete Elixir and Phoenix Bootcamp von Stephen Grinder (Einsehbar auf 哔哩哔哩) - Teil 1: - Teil 2: - Teil 3: Das Beispiel zum MNIST Datensatz der Nx-Library","ref":"readme.html#ressourcen","title":"Elixir Neurales Netz - Ressourcen","type":"extras"}]